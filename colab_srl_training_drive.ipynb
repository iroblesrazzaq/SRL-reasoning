{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0061fd88",
      "metadata": {
        "id": "0061fd88"
      },
      "source": [
        "# SRL GRPO Training (Colab, A100)\n",
        "End-to-end notebook for SRL GRPO training with LoRA.\n",
        "\n",
        "**Features:**\n",
        "- Saves checkpoint to disk AND Drive after each epoch\n",
        "- No validation (removed to avoid failures)\n",
        "- Crash-resilient: progress saved to Drive survives session kills\n",
        "- **Unique run names** for parallel experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mount_drive",
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "#@title 0. Mount Google Drive FIRST\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('‚úì Drive mounted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run_config",
      "metadata": {
        "id": "run_config"
      },
      "outputs": [],
      "source": [
        "#@title 1. ‚ö†Ô∏è SET RUN CONFIG HERE ‚ö†Ô∏è (change for each experiment)\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================\n",
        "# CHANGE THESE FOR EACH EXPERIMENT!\n",
        "# ============================================================\n",
        "# Run name examples:\n",
        "#   RUN_NAME = \"baseline_string\"      # 100% string similarity\n",
        "#   RUN_NAME = \"cosine_only\"          # 100% cosine similarity\n",
        "#   RUN_NAME = \"hybrid_90_10\"         # 90% string + 10% cosine\n",
        "\n",
        "RUN_NAME = \"baseline_string\"  # <-- CHANGE THIS\n",
        "\n",
        "# ============================================================\n",
        "# REWARD FUNCTION WEIGHTS\n",
        "# ============================================================\n",
        "# Three experiment configurations:\n",
        "#   baseline_string:  STRING_WEIGHT=1.0, COSINE_WEIGHT=0.0\n",
        "#   cosine_only:      STRING_WEIGHT=0.0, COSINE_WEIGHT=1.0\n",
        "#   hybrid_90_10:     STRING_WEIGHT=0.9, COSINE_WEIGHT=0.1\n",
        "\n",
        "STRING_WEIGHT = 1.0  # Weight for string similarity (difflib)\n",
        "COSINE_WEIGHT = 0.0  # Weight for cosine similarity (embeddings)\n",
        "\n",
        "# Validate reward weights\n",
        "if STRING_WEIGHT < 0 or COSINE_WEIGHT < 0:\n",
        "    raise ValueError(\"Weights must be non-negative\")\n",
        "if STRING_WEIGHT + COSINE_WEIGHT <= 0:\n",
        "    raise ValueError(\"STRING_WEIGHT + COSINE_WEIGHT must be > 0\")\n",
        "\n",
        "# Embedding model (only loaded if COSINE_WEIGHT > 0)\n",
        "EMBEDDING_MODEL = \"Qwen/Qwen3-Embedding-0.6B\"\n",
        "\n",
        "# ============================================================\n",
        "# Auto-generate paths based on RUN_NAME\n",
        "# ============================================================\n",
        "DRIVE_BASE = Path('/content/drive/MyDrive/srl_outputs')\n",
        "DRIVE_CKPT_DIR = DRIVE_BASE / f'checkpoints_{RUN_NAME}'\n",
        "DRIVE_FINAL_DIR = DRIVE_BASE / f'final_{RUN_NAME}'\n",
        "\n",
        "DISK_CKPT_DIR = Path(f'/content/checkpoints_{RUN_NAME}')\n",
        "OUTPUT_DIR = Path(f'/content/outputs_{RUN_NAME}')\n",
        "\n",
        "# Create directories\n",
        "DRIVE_CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "DISK_CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('=' * 60)\n",
        "print(f'RUN NAME: {RUN_NAME}')\n",
        "print('=' * 60)\n",
        "print(f'  Drive checkpoints: {DRIVE_CKPT_DIR}')\n",
        "print(f'  Drive final:       {DRIVE_FINAL_DIR}')\n",
        "print(f'  Disk checkpoints:  {DISK_CKPT_DIR}')\n",
        "print(f'  Output dir:        {OUTPUT_DIR}')\n",
        "print('=' * 60)\n",
        "\n",
        "# Check for existing checkpoints\n",
        "existing = list(DRIVE_CKPT_DIR.glob('epoch_*'))\n",
        "if existing:\n",
        "    print(f'\\n‚ö†Ô∏è  Found {len(existing)} existing checkpoint(s) for this run:')\n",
        "    for p in sorted(existing):\n",
        "        print(f'      - {p.name}')\n",
        "    print('\\n   (Training will add more checkpoints to this run)')\n",
        "else:\n",
        "    print(f'\\n‚úì Fresh run - no existing checkpoints')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f69b73",
      "metadata": {
        "id": "15f69b73"
      },
      "outputs": [],
      "source": [
        "#@title 2. Environment setup (clone + installs)\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "%env TORCH_CUDA_ARCH_LIST=8.0\n",
        "\n",
        "REPO_URL = \"https://github.com/iroblesrazzaq/SRL-reasoning.git\"\n",
        "REPO_DIR = Path('/content/SRL-reasoning')\n",
        "REPO_DIR_STR = str(REPO_DIR)\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    !git clone $REPO_URL $REPO_DIR_STR\n",
        "\n",
        "os.chdir(REPO_DIR_STR)\n",
        "if REPO_DIR_STR not in sys.path:\n",
        "    sys.path.append(REPO_DIR_STR)\n",
        "\n",
        "!pip install transformers peft bitsandbytes accelerate datasets trl --no-build-isolation\n",
        "!pip install --no-build-isolation --no-cache-dir flash-attn\n",
        "\n",
        "!pip install git+https://github.com/huggingface/trl.git\n",
        "!pip install -e .\n",
        "\n",
        "import torch\n",
        "device_name = torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
        "print(f'PyTorch {torch.__version__} | Device: {device_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c11e5a8",
      "metadata": {
        "id": "3c11e5a8"
      },
      "outputs": [],
      "source": [
        "#@title 3. Global config\n",
        "import random, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "SEED = 42\n",
        "BASE_MODEL = 'Qwen/Qwen3-4B-Instruct-2507'\n",
        "DATA_DIR = REPO_DIR / 'data'\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "print(f'RUN_NAME: {RUN_NAME}')\n",
        "print(f'DATA_DIR: {DATA_DIR}')\n",
        "print(f'OUTPUT_DIR: {OUTPUT_DIR}')\n",
        "print(f'Reward weights: string={STRING_WEIGHT}, cosine={COSINE_WEIGHT}')\n",
        "if COSINE_WEIGHT > 0:\n",
        "    print(f'Embedding model: {EMBEDDING_MODEL}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b515ef21",
      "metadata": {
        "id": "b515ef21"
      },
      "outputs": [],
      "source": [
        "#@title 4. Build SRL data (s1K-1.1 -> step-wise JSONL)\n",
        "from src.shared.build_srl_data import load_teacher_dataset, normalize_dataset, build_srl_dataset, save_jsonl\n",
        "from src.shared.splits import split_by_trajectory\n",
        "\n",
        "raw_ds = load_teacher_dataset('simplescaling/s1K-1.1', split='train')\n",
        "norm_trajs = normalize_dataset(raw_ds)\n",
        "srl_examples = build_srl_dataset(norm_trajs)\n",
        "\n",
        "all_path = DATA_DIR / 'srl_steps.jsonl'\n",
        "save_jsonl(srl_examples, all_path)\n",
        "\n",
        "train_examples, val_examples, _ = split_by_trajectory(\n",
        "    str(all_path),\n",
        "    train_ratio=1.0,\n",
        "    val_ratio=0.0,\n",
        "    test_ratio=0.0,  # Explicitly discard 90%\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "train_path = DATA_DIR / 'train.jsonl'\n",
        "val_path = DATA_DIR / 'val.jsonl'\n",
        "save_jsonl(train_examples, train_path)\n",
        "save_jsonl(val_examples, val_path)\n",
        "\n",
        "print(f'Train examples: {len(train_examples)}')\n",
        "print(f'Val examples:   {len(val_examples)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0359ba",
      "metadata": {
        "id": "5f0359ba"
      },
      "outputs": [],
      "source": [
        "#@title 5. Prepare HF datasets for GRPO (train only - no eval)\n",
        "from scripts.train_srl import load_srl_dataset\n",
        "\n",
        "train_dataset = load_srl_dataset(str(train_path))\n",
        "# NOTE: val_dataset not used - validation removed to avoid failures\n",
        "\n",
        "print(train_dataset[:2])\n",
        "print(f'HF datasets -> train {len(train_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f513bf",
      "metadata": {
        "id": "36f513bf"
      },
      "outputs": [],
      "source": [
        "#@title 6. Load model + tokenizer (LoRA, flash-attn, grad checkpointing)\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    padding_side='left',\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    BASE_MODEL,\n",
        "    attn_implementation='flash_attention_2',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto',\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules='all-linear',\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    bias='none',\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.enable_input_require_grads()\n",
        "model.gradient_checkpointing_enable()\n",
        "model.config.use_cache = False\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f'Trainable params: {trainable_params/1e6:.1f}M / {total_params/1e6:.1f}M')\n",
        "if torch.cuda.is_available():\n",
        "    print('Model device:', next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b341df51",
      "metadata": {
        "id": "b341df51"
      },
      "outputs": [],
      "source": [
        "#@title 7. Configure GRPO trainer (with epoch checkpoints)\n",
        "import shutil\n",
        "from inspect import signature\n",
        "from trl import GRPOConfig\n",
        "from transformers import TrainerCallback\n",
        "from scripts.train_srl import SRLGRPOTrainer, create_reward_function\n",
        "\n",
        "# Create reward function with configured weights\n",
        "reward_fn = create_reward_function(\n",
        "    tokenizer=tokenizer,\n",
        "    string_weight=STRING_WEIGHT,\n",
        "    cosine_weight=COSINE_WEIGHT,\n",
        "    embedding_model_name=EMBEDDING_MODEL,\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# Callback to save after each epoch to disk AND Drive\n",
        "# ============================================================\n",
        "class EpochCheckpointCallback(TrainerCallback):\n",
        "    \"\"\"Save model to disk and Drive after each epoch.\"\"\"\n",
        "    \n",
        "    def __init__(self, trainer_ref, tokenizer, disk_dir, drive_dir, run_name):\n",
        "        self.trainer_ref = trainer_ref\n",
        "        self.tokenizer = tokenizer\n",
        "        self.disk_dir = Path(disk_dir)\n",
        "        self.drive_dir = Path(drive_dir)\n",
        "        self.run_name = run_name\n",
        "        self.last_saved_epoch = -1\n",
        "    \n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        \"\"\"Save checkpoint at end of each epoch.\"\"\"\n",
        "        epoch = int(state.epoch)\n",
        "        \n",
        "        # Avoid duplicate saves\n",
        "        if epoch <= self.last_saved_epoch:\n",
        "            return\n",
        "        self.last_saved_epoch = epoch\n",
        "        \n",
        "        ckpt_name = f'epoch_{epoch}_step_{state.global_step}'\n",
        "        disk_path = self.disk_dir / ckpt_name\n",
        "        drive_path = self.drive_dir / ckpt_name\n",
        "        \n",
        "        print(f'\\n{\"=\"*60}')\n",
        "        print(f'[{self.run_name}] EPOCH {epoch} COMPLETE - SAVING CHECKPOINT')\n",
        "        print(f'{\"=\"*60}')\n",
        "        \n",
        "        # Save to Colab disk (fast)\n",
        "        try:\n",
        "            self.trainer_ref.save_model(str(disk_path))\n",
        "            self.tokenizer.save_pretrained(str(disk_path))\n",
        "            # Verify files were saved\n",
        "            saved_files = list(disk_path.glob('*'))\n",
        "            if not saved_files:\n",
        "                print(f'  ‚úó ERROR: No files saved to {disk_path}')\n",
        "                return\n",
        "            print(f'  ‚úì Saved to disk: {disk_path} ({len(saved_files)} files)')\n",
        "        except Exception as e:\n",
        "            print(f'  ‚úó ERROR saving to disk: {e}')\n",
        "            return  # Don't try Drive if disk save failed\n",
        "        \n",
        "        # Copy to Google Drive (backup) - wrapped in try/except to not crash training\n",
        "        try:\n",
        "            import os as _os\n",
        "            if drive_path.exists():\n",
        "                shutil.rmtree(drive_path)\n",
        "            shutil.copytree(disk_path, drive_path)\n",
        "            _os.sync()  # Force flush to ensure Drive write completes\n",
        "            print(f'  ‚úì Backed up to Drive: {drive_path}')\n",
        "            \n",
        "            # Show Drive contents\n",
        "            existing = list(self.drive_dir.glob('epoch_*'))\n",
        "            print(f'  ‚úì Drive checkpoints for {self.run_name}: {len(existing)}')\n",
        "            for p in sorted(existing)[-3:]:  # Show last 3\n",
        "                print(f'      - {p.name}')\n",
        "            if len(existing) > 3:\n",
        "                print(f'      ... and {len(existing) - 3} more')\n",
        "        except Exception as e:\n",
        "            print(f'  ‚ö†Ô∏è  WARNING: Drive backup failed (disk copy still exists): {e}')\n",
        "            print(f'      Disk checkpoint at: {disk_path}')\n",
        "        \n",
        "        print(f'{\"=\"*60}\\n')\n",
        "\n",
        "# ============================================================\n",
        "# GRPO Config - NO EVALUATION\n",
        "# ============================================================\n",
        "grpo_kwargs = {\n",
        "    'output_dir': str(OUTPUT_DIR),\n",
        "    'num_train_epochs': 30,             # [cite: 235] Matches paper\n",
        "    'per_device_train_batch_size': 4,   # A100 80GB capacity\n",
        "    # Effective batch size: 4 * 32 = 128 (reduced from paper's 512 for memory)\n",
        "    # Note: GRPO generates num_generations=4 per prompt, so actual throughput is higher\n",
        "    'gradient_accumulation_steps': 32,  # [cite: 523]\n",
        "    'learning_rate': 5e-7,              # [cite: 530] Paper uses 5e-7\n",
        "    'beta': 0.0,                        # [cite: 536] KL coeff is 0 for SRL\n",
        "    'warmup_ratio': 0.0,                # [cite: 531] No warmup\n",
        "    'max_grad_norm': 1.0,               # [cite: 525]\n",
        "    'num_generations': 4,               # [cite: 534]\n",
        "    'temperature': 1.0,                 # [cite: 533] Explicitly set rollout temp\n",
        "    'max_prompt_length': 512,           # Max input prompt tokens\n",
        "    'max_completion_length': 256,       # Max generated tokens per completion\n",
        "\n",
        "    # === SAVE STRATEGY ===\n",
        "    'save_strategy': 'no',              # We handle saves manually via callback\n",
        "    \n",
        "    # === NO EVALUATION (removed to avoid failures) ===\n",
        "    'evaluation_strategy': 'no',        # No validation - was causing failures\n",
        "    'load_best_model_at_end': False,    # Disabled since no eval\n",
        "    \n",
        "    # Convention / Engineering settings\n",
        "    'logging_steps': 1,\n",
        "    'optim': 'adamw_8bit',              # Convention (Paper uses H100s, likely 8bit or full)\n",
        "    'bf16': True,                       # [cite: 527]\n",
        "    'report_to': 'none',\n",
        "    'seed': SEED,\n",
        "}\n",
        "\n",
        "supported = set(signature(GRPOConfig.__init__).parameters)\n",
        "grpo_config = GRPOConfig(**{k: v for k, v in grpo_kwargs.items() if k in supported})\n",
        "\n",
        "# Create trainer (NO eval_dataset)\n",
        "# Check if GRPOTrainer accepts 'tokenizer' parameter (TRL version compatibility)\n",
        "# Note: Check GRPOTrainer (parent), not SRLGRPOTrainer (which uses **kwargs)\n",
        "from trl import GRPOTrainer\n",
        "_grpo_params = set(signature(GRPOTrainer.__init__).parameters)\n",
        "_trainer_kwargs = {\n",
        "    \"model\": model,\n",
        "    \"args\": grpo_config,\n",
        "    \"train_dataset\": train_dataset,\n",
        "    \"reward_funcs\": reward_fn,\n",
        "    \"filter_epsilon\": 1e-4,\n",
        "}\n",
        "# TRL versions vary - some use 'tokenizer', some use 'processing_class'\n",
        "if \"tokenizer\" in _grpo_params:\n",
        "    _trainer_kwargs[\"tokenizer\"] = tokenizer\n",
        "elif \"processing_class\" in _grpo_params:\n",
        "    _trainer_kwargs[\"processing_class\"] = tokenizer\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Warning: Neither 'tokenizer' nor 'processing_class' found in GRPOTrainer params\")\n",
        "\n",
        "trainer = SRLGRPOTrainer(**_trainer_kwargs)\n",
        "\n",
        "# Add epoch checkpoint callback\n",
        "epoch_callback = EpochCheckpointCallback(\n",
        "    trainer_ref=trainer,\n",
        "    tokenizer=tokenizer,\n",
        "    disk_dir=DISK_CKPT_DIR,\n",
        "    drive_dir=DRIVE_CKPT_DIR,\n",
        "    run_name=RUN_NAME,\n",
        ")\n",
        "trainer.add_callback(epoch_callback)\n",
        "\n",
        "print('=' * 60)\n",
        "print(f'TRAINING CONFIG - {RUN_NAME}')\n",
        "print('=' * 60)\n",
        "print(f'  Run name: {RUN_NAME}')\n",
        "print(f'  Epochs: {grpo_kwargs[\"num_train_epochs\"]}')\n",
        "print(f'  Batch size: {grpo_kwargs[\"per_device_train_batch_size\"]} x {grpo_kwargs[\"gradient_accumulation_steps\"]} = {grpo_kwargs[\"per_device_train_batch_size\"] * grpo_kwargs[\"gradient_accumulation_steps\"]}')\n",
        "print(f'  Max prompt length: {grpo_kwargs[\"max_prompt_length\"]}')\n",
        "print(f'  Max completion length: {grpo_kwargs[\"max_completion_length\"]}')\n",
        "print(f'  Learning rate: {grpo_kwargs[\"learning_rate\"]}')\n",
        "total_w = STRING_WEIGHT + COSINE_WEIGHT\n",
        "print(f'  Reward weights: string={STRING_WEIGHT/total_w:.2f}, cosine={COSINE_WEIGHT/total_w:.2f}')\n",
        "if COSINE_WEIGHT > 0:\n",
        "    print(f'  Embedding model: {EMBEDDING_MODEL}')\n",
        "print(f'  ‚úì Validation: DISABLED')\n",
        "print(f'  ‚úì Checkpoint after each epoch to:')\n",
        "print(f'      - Disk: {DISK_CKPT_DIR}')\n",
        "print(f'      - Drive: {DRIVE_CKPT_DIR}')\n",
        "print('=' * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "train_cell",
      "metadata": {
        "id": "train_cell"
      },
      "outputs": [],
      "source": [
        "#@title 8. TRAIN (checkpoints saved after each epoch)\n",
        "# Check if we should resume from a checkpoint\n",
        "resume_checkpoint = None\n",
        "if 'RESUME_FROM' in dir() and RESUME_FROM:\n",
        "    resume_checkpoint = RESUME_FROM\n",
        "    print(f'\\nüîÑ RESUMING TRAINING: {RUN_NAME}')\n",
        "    print(f'   From checkpoint: {resume_checkpoint}')\n",
        "else:\n",
        "    print(f'\\nüöÄ STARTING TRAINING: {RUN_NAME}')\n",
        "\n",
        "print('Progress is backed up to Drive after each epoch.')\n",
        "print('If session dies, your checkpoints are safe!\\n')\n",
        "\n",
        "train_result = trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
        "print(train_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff31ede1",
      "metadata": {
        "id": "ff31ede1"
      },
      "outputs": [],
      "source": [
        "#@title 9. Save final model to Google Drive\n",
        "DRIVE_FINAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "trainer.save_model(str(DRIVE_FINAL_DIR))\n",
        "tokenizer.save_pretrained(str(DRIVE_FINAL_DIR))\n",
        "import os\n",
        "os.sync()  # Ensure final model is written to Drive\n",
        "\n",
        "print('=' * 60)\n",
        "print(f'TRAINING COMPLETE - {RUN_NAME}')\n",
        "print('=' * 60)\n",
        "print(f'Final model saved to: {DRIVE_FINAL_DIR}')\n",
        "print(f'Epoch checkpoints at: {DRIVE_CKPT_DIR}')\n",
        "\n",
        "# List all checkpoints\n",
        "print('\\nAll saved checkpoints:')\n",
        "for p in sorted(DRIVE_CKPT_DIR.glob('epoch_*')):\n",
        "    print(f'  - {p.name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "resume_section",
      "metadata": {
        "id": "resume_section"
      },
      "source": [
        "---\n",
        "# Resume Training from Checkpoint\n",
        "\n",
        "If your session crashed, follow these steps to resume:\n",
        "\n",
        "1. Run **Cells 0-6** (with the **same `RUN_NAME`**!)\n",
        "2. Run the **Resume cell below** to set `RESUME_FROM`\n",
        "3. Run **Cell 7** (Configure GRPO trainer)\n",
        "4. Run **Cell 8** (TRAIN) - it will automatically resume from the checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "resume_cell",
      "metadata": {
        "id": "resume_cell"
      },
      "outputs": [],
      "source": [
        "#@title [OPTIONAL] Resume from Drive checkpoint\n",
        "# Run this cell BEFORE Cell 8 (TRAIN) to resume from a checkpoint.\n",
        "# After running this cell, run Cell 7 (Configure GRPO) then Cell 8 (TRAIN).\n",
        "\n",
        "print(f'Looking for checkpoints for run: {RUN_NAME}')\n",
        "print(f'Directory: {DRIVE_CKPT_DIR}')\n",
        "print()\n",
        "\n",
        "RESUME_FROM = None  # Initialize to None\n",
        "checkpoints = sorted(DRIVE_CKPT_DIR.glob('epoch_*'))\n",
        "if checkpoints:\n",
        "    print(f'Found {len(checkpoints)} checkpoint(s):')\n",
        "    for i, p in enumerate(checkpoints):\n",
        "        print(f'  [{i}] {p.name}')\n",
        "    \n",
        "    # Use most recent checkpoint\n",
        "    RESUME_FROM = str(checkpoints[-1])\n",
        "    print(f'\\n‚úì RESUME_FROM set to: {RESUME_FROM}')\n",
        "    print('\\n‚ö†Ô∏è  Now run Cell 7 (Configure GRPO) then Cell 8 (TRAIN) to resume.')\n",
        "else:\n",
        "    print('No checkpoints found - start fresh training.')\n",
        "    print('Run Cell 7 and Cell 8 normally.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "compare_section",
      "metadata": {
        "id": "compare_section"
      },
      "source": [
        "---\n",
        "# Compare All Runs\n",
        "\n",
        "List all experiment runs saved in Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compare_cell",
      "metadata": {
        "id": "compare_cell"
      },
      "outputs": [],
      "source": [
        "#@title List all runs in Drive\n",
        "print('All SRL training runs in Drive:')\n",
        "print('=' * 60)\n",
        "\n",
        "checkpoint_dirs = sorted(DRIVE_BASE.glob('checkpoints_*'))\n",
        "final_dirs = sorted(DRIVE_BASE.glob('final_*'))\n",
        "\n",
        "if checkpoint_dirs:\n",
        "    print('\\nCheckpoint directories:')\n",
        "    for d in checkpoint_dirs:\n",
        "        run_name = d.name.replace('checkpoints_', '')\n",
        "        epochs = list(d.glob('epoch_*'))\n",
        "        print(f'  {run_name}: {len(epochs)} checkpoint(s)')\n",
        "\n",
        "if final_dirs:\n",
        "    print('\\nFinal models:')\n",
        "    for d in final_dirs:\n",
        "        run_name = d.name.replace('final_', '')\n",
        "        print(f'  {run_name}')\n",
        "\n",
        "if not checkpoint_dirs and not final_dirs:\n",
        "    print('No runs found yet.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
