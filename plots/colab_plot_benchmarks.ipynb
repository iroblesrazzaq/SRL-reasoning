{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Results Plotting\n",
    "\n",
    "Plot benchmark results from Google Drive.\n",
    "\n",
    "**Features:**\n",
    "- Models on x-axis, grouped by benchmark (AMC23/AIME25) and eval type (Greedy/Avg@32)\n",
    "- Solid bars = Greedy, Hatched bars = Avg@32\n",
    "- Green = AMC23, Blue = AIME25\n",
    "- Auto-discovers models from result files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting functions\n",
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/SRL-reasoning/plots')\n",
    "\n",
    "from plot_benchmarks import (\n",
    "    plot_benchmark_results,\n",
    "    list_available_results,\n",
    "    DRIVE_RESULTS_FOLDER,\n",
    ")\n",
    "\n",
    "print(f\"Results folder: {DRIVE_RESULTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Available Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what results are available\n",
    "list_available_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot All Results\n",
    "\n",
    "Generate a bar chart with all models, benchmarks, and eval types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all results - saves PDF locally by default\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    output_filename='all_benchmarks.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Plots\n",
    "\n",
    "Examples of filtering by benchmark, eval type, or model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only AMC23 results\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks=['amc23'],\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    output_filename='amc23_results.pdf',\n",
    "    title='AMC23 Performance',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only AIME25 results\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks=['aime25'],\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    output_filename='aime25_results.pdf',\n",
    "    title='AIME25 Performance',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only Greedy results (both benchmarks)\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types=['greedy'],\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    output_filename='greedy_results.pdf',\n",
    "    title='Greedy Decoding Performance',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only Avg@32 results (both benchmarks)\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types=['avg32'],\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    output_filename='avg32_results.pdf',\n",
    "    title='Avg@32 Performance',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Google Drive\n",
    "\n",
    "Use `save_to_drive=True` to save PDF directly to Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save plot to Drive (same folder as results)\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    save_to_drive=True,\n",
    "    output_filename='benchmark_results.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to custom Drive path\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=True,\n",
    "    save_to_drive=True,\n",
    "    drive_save_path='/content/drive/MyDrive/plots',\n",
    "    output_filename='benchmark_results.pdf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Only (No Save)\n",
    "\n",
    "Use `save_pdf=False` to just display the plot without saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just display, don't save\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types='all',\n",
    "    models='all',\n",
    "    save_pdf=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by Specific Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot specific models only\n",
    "# Use model short names (without repo prefix) or full paths\n",
    "fig = plot_benchmark_results(\n",
    "    benchmarks='all',\n",
    "    eval_types='all',\n",
    "    models=['Qwen3-4B-Instruct-2507'],  # Add more models to this list\n",
    "    save_pdf=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
